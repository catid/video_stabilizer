#ifndef sparse_ica_SCHEDULE_H
#define sparse_ica_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Adams2019
// for target=x86-64-linux-avx-avx2-enable_llvm_loop_opt-f16c-fma-sse41  // NOLINT
// with autoscheduler_params=autoscheduler=Adams2019

#include "Halide.h"


inline void apply_schedule_sparse_ica(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target
) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;
    Func output = pipeline.get_func(20);
    Func f3 = pipeline.get_func(19);
    Func f1 = pipeline.get_func(17);
    Func sum_3 = pipeline.get_func(16);
    Func sum_2 = pipeline.get_func(15);
    Func weight_y_1 = pipeline.get_func(14);
    Func weight_x_1 = pipeline.get_func(13);
    Func f2 = pipeline.get_func(11);
    Func f0 = pipeline.get_func(8);
    Func sum_1 = pipeline.get_func(7);
    Func sum = pipeline.get_func(6);
    Func weight_y = pipeline.get_func(5);
    Func weight_x = pipeline.get_func(4);
    Func repeat_edge = pipeline.get_func(2);
    Func lambda_0 = pipeline.get_func(1);
    Var i(f1.get_schedule().dims()[0].var);
    Var ii("ii");
    Var iii("iii");
    Var iiii("iiii");
    Var iiiii("iiiii");
    Var v0(output.get_schedule().dims()[0].var);
    Var v0i("v0i");
    Var v12(weight_y_1.get_schedule().dims()[1].var);
    Var v2(f3.get_schedule().dims()[0].var);
    Var v2i("v2i");
    RVar r_x(f3.update(0).get_schedule().dims()[0].var);
    RVar rxy_x(sum_3.update(0).get_schedule().dims()[0].var);
    RVar rxy_y(sum_3.update(0).get_schedule().dims()[1].var);
    output
        .split(v0, v0, v0i, 8, TailStrategy::GuardWithIf)
        .vectorize(v0i)
        .compute_root()
        .reorder({v0i, v0});
    f3
        .split(v2, v2, v2i, 8, TailStrategy::RoundUp)
        .vectorize(v2i)
        .compute_root()
        .reorder({v2i, v2});
    f3.update(0)
        .reorder({r_x});
    f3.update(1)
        .reorder({r_x});
    f3.update(2)
        .reorder({r_x});
    f3.update(3)
        .reorder({r_x});
    f1
        .split(i, i, ii, 64, TailStrategy::GuardWithIf)
        .split(ii, ii, iii, 32, TailStrategy::ShiftInwards)
        .split(iii, iii, iiii, 16, TailStrategy::ShiftInwards)
        .split(iiii, iiii, iiiii, 8, TailStrategy::ShiftInwards)
        .unroll(iiii)
        .vectorize(iiiii)
        .compute_root()
        .reorder({iiiii, iiii, iii, ii, i})
        .parallel(i);
    sum_3
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 8, TailStrategy::RoundUp)
        .unroll(i)
        .vectorize(ii)
        .compute_at(f1, iii)
        .reorder({ii, i});
    sum_3.update(0)
        .split(i, i, ii, 8, TailStrategy::RoundUp)
        .unroll(i)
        .vectorize(ii)
        .reorder({ii, i, rxy_x, rxy_y});
    sum_2
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 8, TailStrategy::RoundUp)
        .unroll(i)
        .vectorize(ii)
        .compute_at(f1, ii)
        .reorder({ii, i});
    sum_2.update(0)
        .split(i, i, ii, 32, TailStrategy::GuardWithIf)
        .vectorize(ii)
        .reorder({ii, i, rxy_x, rxy_y});
    weight_y_1
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 16, TailStrategy::ShiftInwards)
        .unroll(i)
        .unroll(v12)
        .vectorize(ii)
        .compute_at(f1, ii)
        .reorder({ii, i, v12});
    weight_x_1
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 16, TailStrategy::ShiftInwards)
        .unroll(i)
        .unroll(v12)
        .vectorize(ii)
        .compute_at(f1, ii)
        .reorder({ii, i, v12});
    f2
        .split(v2, v2, v2i, 8, TailStrategy::RoundUp)
        .vectorize(v2i)
        .compute_root()
        .reorder({v2i, v2});
    f2.update(0)
        .reorder({r_x});
    f2.update(1)
        .reorder({r_x});
    f2.update(2)
        .reorder({r_x});
    f2.update(3)
        .reorder({r_x});
    f0
        .split(i, i, ii, 128, TailStrategy::GuardWithIf)
        .split(ii, ii, iii, 32, TailStrategy::ShiftInwards)
        .split(iii, iii, iiii, 8, TailStrategy::ShiftInwards)
        .unroll(iii)
        .vectorize(iiii)
        .compute_root()
        .reorder({iiii, iii, ii, i})
        .parallel(i);
    sum_1
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 8, TailStrategy::RoundUp)
        .vectorize(ii)
        .compute_at(f0, iii)
        .reorder({ii, i});
    sum_1.update(0)
        .split(i, i, ii, 8, TailStrategy::RoundUp)
        .vectorize(ii)
        .reorder({ii, i, rxy_x, rxy_y});
    sum
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 8, TailStrategy::RoundUp)
        .unroll(i)
        .vectorize(ii)
        .compute_at(f0, ii)
        .reorder({ii, i});
    sum.update(0)
        .split(i, i, ii, 32, TailStrategy::GuardWithIf)
        .vectorize(ii)
        .reorder({ii, i, rxy_x, rxy_y});
    weight_y
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 16, TailStrategy::ShiftInwards)
        .unroll(i)
        .unroll(v12)
        .vectorize(ii)
        .compute_at(f0, ii)
        .reorder({ii, i, v12});
    weight_x
        .store_in(MemoryType::Stack)
        .split(i, i, ii, 16, TailStrategy::ShiftInwards)
        .unroll(i)
        .unroll(v12)
        .vectorize(ii)
        .compute_at(f0, ii)
        .reorder({ii, i, v12});

}

#endif  // sparse_ica_SCHEDULE_H
